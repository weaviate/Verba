{
    "text": "\n\n -->\n\nimport PreviewUnit from '../../_snippets/preview.mdx'\n\n\n\n## &nbsp;&nbsp;Overview\n\nNow that you've learned about what chunking is, and why it is important, you are ready to start looking at practical chunking techniques. Here, we start by looking at **fixed-size** chunking techniques, including some example implementations.\n\n## &nbsp;&nbsp;Fixed-size chunking\n\nAs the name suggests, fixed-size chunking refers to the process of splitting texts into chunks of a fixed size, or at least based on size. Using fixed size chunking, you might split an article into a set of chunks of 100 words each, or a set of 200 characters each.\n\nThis may be the most common chunking technique due to its simplicity and effectiveness.\n\n### &nbsp;&nbsp;Implementations\n\nFixed-size chunking is implemented by splitting texts into chunks of a fixed number of units. The units may be composed of words, characters, or even *tokens*, and the number of units per chunk is fixed (to a maximum), with an optional overlap.\n\nA \"token\" in this context is a unit of text that will be processed by a model by being substituted with a number. In modern tranformer models, a token is commonly a \"subword\" unit composed of a few characters.\n\nOne pseudocode implementation of fixed-size chunking is:\n\n```python\n# Given a text of length L\n# Split the text into chunks of size N units (e.g. tokens, characters, words)\n# Optionally, add an overlap of M units at the beginning or end of each chunk (from the previous or next chunk)\n# This should typically result in a list of chunks of length L // N + 1\n```\n\nAnd implementing in Python, it may look like:\n\n\n\n\n\n\n\nWhich can be modified to include an overlap (in this case, at the beginning of each chunk):\n\n\n\n\n\n\n\nThis is far from the only way to implement fixed-size chunking, but it is one possible, relatively simple, implementation.\n\nConsider how *you* might implement fixed-size chunking. What would your pseudocode (or code) look like?\n\n### &nbsp;&nbsp;Examples\n\nWe are ready to look at some concrete examples of fixed-size chunking. Let's take a look at three examples, with a chunk size of 5 words, 25 words and 100 words, respectively.\n\nWe'll use an excerpt from the Pro Git book*. More specifically, we'll use text of the What is Git? chapter.\n\nHere is one example using our chunking function from above:\n\n\n\n\n\n\n\nThis will result in outputs like these. Take a look at the first few chunks at each size - what do you notice?\n\nConsider which of these chunk sizes would be most appropriate for search. Why do you think so? What are the tradeoffs?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHopefully, these concrete examples start to illustrate some of the ideas that we discussed above.\n\nImmediately, it strikes me that the smaller chunks are very granular, to the point where they may not contain enough information to be useful for search. On the other hand, the larger chunks begin to retain more information as they get to lengths that are similar to a typical paragraph.\n\nNow imagine these chunks becoming even longer. As chunks become longer, the corresponding vector embeddings would start to become more general. This would eventually reach a point where they cease to be useful in terms of searching for information.\n\nAt these sizes, you typically will not need to employ character-based or sub-word token-based chunking, as splitting words at these boundaries in a group of words will not typically be meaningful.\n\nFor search with fixed-size chunks, if you don't have any other factors, try a size of around 100-200 words, and a 20% overlap.\n\n## &nbsp;&nbsp;Notes\n\n\n*Available through the Creative Commons Attribution-Non Commercial-Share Alike 3.0 license.\n\n\n&nbsp;&nbsp;Review\n\n\n\nAny quiz questions\n\n### &nbsp;&nbsp;Review exercise\n\nTry out ...\n\n### &nbsp;&nbsp;Key takeaways\n\nAdd summary\n\n\n\n\n",
    "type": "Documentation",
    "name": "chunking-how_1",
    "path": "developers/academy/standalone/chunking/20_how_1.mdx",
    "link": "https://weaviate.io/developers/academy/standalone/chunking/how_1",
    "timestamp": "2024-02-08 21:19:39",
    "reader": "JSON",
    "meta": {},
    "chunks": []
}